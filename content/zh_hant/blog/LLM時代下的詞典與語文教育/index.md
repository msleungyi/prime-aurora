---
title: 當ChatGPT遇上《牛津詞典》：我們還需要「標準答案」嗎？
summary: ""
date: 2026-02-26T11:00:00.000Z
draft: false
image:
  filename: featured.jpg
  caption: "Image credit: [**Unsplash**](https://unsplash.com)"
cover:
  image: https://images.unsplash.com/photo-1648957169152-0025a4fc0888?q=80&w=1170&auto=format&fit=crop&ixlib=rb-4.1.0&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D
  position:
    x: 50
    y: 40
  overlay:
    enabled: true
    type: gradient
    opacity: 0.4
    gradient: bottom
  fade:
    enabled: true
    height: 80px
  icon:
    name: 💡
authors:
  - me.zh-hant
tags:
  - 人工智能
  - 中文教育
content_meta:
  trending: false

---

我最近跟以前香港教育系的老同學策劃一個有關語文教學的Podcast節目，我們聊到AI對教學的衝擊。這篇網誌想聊聊：在一個「問AI便有答案」的時代，詞典這塊「老招牌」還有什麼不可替代的溫情與權威？

## 教室裡的「新常態」：AI說的都對？
AI是一個很廣泛的概念，而這篇文章僅指Large Language Models (LLM; 大語言模型）。LLM，比如ChatGPT、DeepSeek、Google Gemini，能通過海量的文本訓練，預測並聲稱自然對話的AI。我的老同學分享，現在的小學學生若碰到不理解的詞語，一般會先問LLM取答案。但每當查找古漢語的詞義，LLM所給的答案放在該課文裡去理解，似乎不通。我的老同學便讓她的學生查看古漢語詞典，怎料孩子說：「詞典？是怎麼查的？」

這個問題讓我陷入了深思。曾幾何時，翻閱部首、數筆畫、對照義項，是我們學生年代學習新詞的必經之路。但在LLM橫行的今天，孩子習慣了「餵養式」的答案，卻逐漸失去了「檢索和裁斷」的能力。

為了驗證LLM有多可信，我特地在ChatGPT和詞典查找生僻字————「豵」的意思。

我先問了ChatGPT 5.2：「豵的意思」。它很親切地告訴我，「豵」字的本義是「小豬、幼豬」，還補充說現在大家都直接說「豬仔」了。聽起來非常合理，對吧？但當我轉向語文教師常用的權威詞典《漢典》時，查閱的結果則不盡相同。

《漢典》的詳細說明指出「豵」可以解「公豬」（出自《玉篇》），亦可解作「出生六個月的小豬」（出自《說文解字》）。相較於ChatGPT的答案，《漢典》中「豵」的解釋並非泛指任何小豬，而是精確到「公」豬，或「出生六個月」的豬。

古漢語的釋詞往往要結合文本所生的年代、語境和語用習慣而定。如果學生給LLM的指令簡單，又或LLM的語料庫尚未涉獵大量古漢語語料，檢閱結果當然可能會差強人意。

這就是LLM帶來的「機率性擬真」。AI目前並未具備對文化脈絡的深度理解，它給出的答案往往是語料庫中的「最大公約數」，容易以現代語感進行「過度推論」。對於初學者而言，這種張冠李戴的解釋，會容易讓他們誤以為語言學習只是詞彙的代換，卻忽略了文字背後那根跨越千年的底蘊。

這種差異也解釋了為何老師對詞典有著執著。在師範訓練中，教授推薦的權威詞典代表了一種知識的傳承與規範。如果失去了這份對精確度的追求，語言學習就會變的像機率預測一樣欠精準。

## 實驗室裡的堅持：標準答案是怎麼被「造」出來的？
轉向我的研究領域————心理語言學（Psycholinguistics），情況變得更有趣。在實驗室設計語文認知測試時，我們同樣需要一個基準，但我們對於「權威」的定義，與語文教師截然不同。

心理學或語言學學者說認可的權威，通常是來自權威實驗室說發布的大型語料庫（Corpus）。與詞典追求「質的規範」不同，語料庫的強項更在乎「量」。語料數據可能抓取自書籍、兒童讀物、甚至電影字幕。對研究員而言，語料庫不一定代表「正確」，但它代表了「真實」，目的是呈現大眾在現實生活中到底是如何使用語言的。

然而，這種基於「量」的權威，在實際中面臨著巨大的難題。

舉例來說，在設計詞彙量測試（Vocabulary Size Test）時，研究員最頭痛的就是設計「正確答案」。你可能見過這種測試：讓受試者從A、B、C、D中選出最準確的詞義。但由於語料來源比較廣泛且混雜，有時候研究員也會發現，選項中也有模棱兩可的答案，設計百分之百精確的選項是具挑戰性的。

這正是研究員與教師殊途同歸的地方。雖然我們沒有像教師那樣對特定詞典又著深厚的執著，但我們依然在尋求一種穩定性。如果我們說依賴的語料庫本身就缺乏詞典那樣的規範邊界，而現在又加上LLM這種具隨機性、會自行「腦補」定義的AI干擾，我們該如何確保測試的信度（reliability）和效度（Validity）？如果「尺」的刻度（語料基準）本身就是模糊的，我們還能準確測量人類大腦對語言的真實反應嗎？

## 給老師與研究者的建議：從尋找答案到「交叉驗證」

雖然教師和心理語言學研究員或許對「權威」的取徑不同：教師守護的是學術的正統血脈，心理語言學追求的是大規模數據的穩健性（Robustness）。但本質上，我們都在做同一件事：守護對語言結構的深度理解。

在 AI 橫行的時代，無論是老師堅持的「規範」，還是研究員追求的「座標」，目的皆是防止稀釋知識。

### 這對教師和家長來說意味著什麼？
其實，這給了我們一個很棒的教育契機。當孩子拿著 AI 給出的答案來找我們時，不要只看結果對不對，而是要引導他們做**「交叉驗證」**。我們可以告訴孩子：

- LLM 是你的「Brainstorming Buddy」： 它可以幫你快速檢索答案、模擬對話、擴散思維。但是...

- 詞典與權威語料是你的「方向盤」： 當你要做最終裁斷、確保沒有「張冠李戴」時，必須回歸那個具備學界共識的基準。

於孩子而言，這不只是在學語文，更是在培養一種**「不盲從數據機率」**的判斷力。

## 結語
上述討論的只是冰山一角。關於 AI 與權威的博弈，還有太多值得深挖的議題，或許值得在之後發布的podcast裡深入探討。比如：

- 如何寫出「精準指令」 (Prompts)： 如何精確、系統地寫指令，讓 LLM 真正輔助我們在語境中準確解釋詞義。

- 詞典的匠心與局限： 詞典不僅是工具，它背後是無數訓詁學家耗費數十年的嚴謹編校。這種深度與厚度，是瞬間生成的 AI 永遠無法取代的「匠心」。當然，詞典也有不足，比如更新速度難以趕上網絡新詞。我們該如何在快節奏的思維時代傳承下去？

- 跨文化的權威觀： 不同國家、不同語言圈對「權威」的定義是否不同？

在這個標準模糊的時代，無論是學生、老師、研究員，還是家長，我們追求的不再只是尋求答案的捷徑。在數據汪洋中，擁有辨別訊息真偽的能力，才是重中之重。